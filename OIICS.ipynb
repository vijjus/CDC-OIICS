{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, LSTM, concatenate, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.14.0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/vijjus/datasets/cdc_train_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(data['event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = sorted(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict = {}\n",
    "for i, e in enumerate(events):\n",
    "    if e not in event_dict:\n",
    "        event_dict[e] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there are many words that only occur in one category, and similarly many that occur in a small number of categories.\n",
    "\n",
    "The first option would be to try an LSTM encoder that feeds into a feedforward layer with a final 48-way softmax to produce the right value.\n",
    "\n",
    "* Input: fixed length vector of text {batch_size x seq_length x embedding_size}\n",
    "* N x GRU unit: taking in each input and producing a final hidden vector without dropout\n",
    "* Feedforward Layer, taking input & output of GRU units to produce output dimension 48\n",
    "* Softmax Layer: final layer for output calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path=\"/home/vijjus/glove/glove.6B.50d.txt\"\n",
    "embedding_size=50\n",
    "text_len=150\n",
    "dropout=0.3\n",
    "learning_rate=0.01\n",
    "max_gradient_norm=10\n",
    "batch_size=32\n",
    "num_labels=len(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1018/400000 [00:00<00:39, 10179.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GLoVE vectors from file: /home/vijjus/glove/glove.6B.50d.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:06<00:00, 63898.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load embedding matrix and vocab mappings\n",
    "from vocab import get_glove\n",
    "emb_matrix, word2id, id2word = get_glove(glove_path, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XY(data):\n",
    "    unknowns = 0\n",
    "    total_len = len(data)\n",
    "    y = np.zeros((total_len,num_labels), dtype=np.float32)\n",
    "    X = np.zeros((total_len,text_len,embedding_size), dtype=np.float32)\n",
    "    for i in tqdm_notebook(range(total_len)):\n",
    "        y[i][event_dict[data.iloc[i]['event']]] = 1\n",
    "        text = data.iloc[i]['text'].lower()\n",
    "        tokens = text.split(\" \")\n",
    "        for j, token in enumerate(tokens):\n",
    "            if token in word2id:\n",
    "                X[i][j] = emb_matrix[word2id[token]]\n",
    "            else:\n",
    "                raise ValueError(\"Token %s not found\" %(token))\n",
    "    print(\"{} tokens not in embedding dictionary\".format(unknowns))\n",
    "    return X, y               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e92a5c67ce34f92a091f26f0598ef02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=153956), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 tokens not in embedding dictionary\n"
     ]
    }
   ],
   "source": [
    "X,Y = get_XY(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(X.shape[0] * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:train_size], Y[:train_size]\n",
    "X_test, y_test = X[train_size:], Y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107769, 150, 50)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46187, 150, 50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate batches\n",
    "def get_batch(X, Y):\n",
    "    indices = np.random.randint(len(X), size=batch_size)\n",
    "    return X[indices], Y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(text_len,embedding_size))\n",
    "output_1 = LSTM(100)(inputs)\n",
    "output_2 = LSTM(100,go_backwards=True)(inputs)\n",
    "d = concatenate([output_1, output_2])\n",
    "d = Dropout(dropout)(d)\n",
    "d = Dense(100)(d)\n",
    "predictions = Dense(num_labels, activation='softmax', name='main_output')(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 50)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 100)          60400       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 100)          60400       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          20100       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 48)           4848        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 145,748\n",
      "Trainable params: 145,748\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'lstm_2/kernel:0' shape=(50, 400) dtype=float32, numpy=\n",
       " array([[ 0.08828513,  0.09555852,  0.10969433, ...,  0.05291204,\n",
       "         -0.05420067, -0.00229403],\n",
       "        [ 0.06844737,  0.07254052,  0.01860087, ...,  0.09238875,\n",
       "         -0.00921651, -0.06601463],\n",
       "        [ 0.10740297, -0.11267237,  0.00013068, ..., -0.04958347,\n",
       "         -0.044721  , -0.0586406 ],\n",
       "        ...,\n",
       "        [-0.00141679, -0.06255758, -0.00490578, ..., -0.00791551,\n",
       "          0.0258543 , -0.09531318],\n",
       "        [-0.05129797,  0.10187654,  0.10733593, ...,  0.0045872 ,\n",
       "         -0.04059001, -0.1099046 ],\n",
       "        [-0.07093757,  0.10397485,  0.07792698, ..., -0.02630445,\n",
       "         -0.0554563 ,  0.06727421]], dtype=float32)>,\n",
       " <tf.Variable 'lstm_2/recurrent_kernel:0' shape=(100, 400) dtype=float32, numpy=\n",
       " array([[ 0.05381787, -0.04817013,  0.04572508, ...,  0.06341285,\n",
       "         -0.01958219, -0.00405331],\n",
       "        [-0.00866438,  0.0121907 , -0.01266572, ...,  0.02328013,\n",
       "          0.05462762,  0.04961293],\n",
       "        [-0.01903974,  0.03820632,  0.05879843, ..., -0.06442676,\n",
       "         -0.02510362, -0.13387442],\n",
       "        ...,\n",
       "        [-0.01441445, -0.01431823,  0.0099355 , ...,  0.10264141,\n",
       "         -0.00227309, -0.01483325],\n",
       "        [ 0.03381335,  0.01846615,  0.03502185, ..., -0.00480868,\n",
       "         -0.07352414,  0.05761898],\n",
       "        [-0.05721281, -0.02359862,  0.02335705, ...,  0.00635435,\n",
       "          0.02101837,  0.02172213]], dtype=float32)>,\n",
       " <tf.Variable 'lstm_2/bias:0' shape=(400,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'lstm_3/kernel:0' shape=(50, 400) dtype=float32, numpy=\n",
       " array([[-0.01435898, -0.03446724,  0.11279304, ..., -0.03460181,\n",
       "          0.0698144 , -0.06713301],\n",
       "        [ 0.04180194,  0.01323187, -0.09933075, ..., -0.00633354,\n",
       "          0.10173137,  0.07988706],\n",
       "        [ 0.03606336, -0.08709591, -0.03268978, ..., -0.05460355,\n",
       "         -0.01115048, -0.03310207],\n",
       "        ...,\n",
       "        [-0.01995774, -0.039001  , -0.02870277, ...,  0.01636916,\n",
       "          0.095939  , -0.10424216],\n",
       "        [-0.0069962 ,  0.10565193, -0.03996576, ...,  0.11046799,\n",
       "         -0.05729947, -0.10590427],\n",
       "        [ 0.03216897,  0.03368591,  0.00490393, ..., -0.08282509,\n",
       "         -0.06572798, -0.09027565]], dtype=float32)>,\n",
       " <tf.Variable 'lstm_3/recurrent_kernel:0' shape=(100, 400) dtype=float32, numpy=\n",
       " array([[-0.04605246,  0.00569232,  0.01728109, ...,  0.0240375 ,\n",
       "          0.08101507,  0.04127514],\n",
       "        [-0.10801408,  0.02973855, -0.00944968, ..., -0.03272654,\n",
       "         -0.1076788 ,  0.01060615],\n",
       "        [ 0.08561012,  0.00114043,  0.08402073, ..., -0.01601733,\n",
       "          0.04273706,  0.04786556],\n",
       "        ...,\n",
       "        [-0.01128791,  0.02281732,  0.05568473, ...,  0.00145251,\n",
       "         -0.05835709, -0.05696551],\n",
       "        [-0.01324496, -0.05512282,  0.08227025, ..., -0.00835428,\n",
       "          0.04723959,  0.06866476],\n",
       "        [-0.01409894, -0.00579084,  0.16951363, ..., -0.02054428,\n",
       "          0.02633806,  0.02850313]], dtype=float32)>,\n",
       " <tf.Variable 'lstm_3/bias:0' shape=(400,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(200, 100) dtype=float32, numpy=\n",
       " array([[ 0.01272899, -0.00059997, -0.07739453, ..., -0.10799035,\n",
       "          0.13259609,  0.04746352],\n",
       "        [ 0.05408989,  0.04523838,  0.00956827, ...,  0.07862191,\n",
       "          0.03458661, -0.10453758],\n",
       "        [-0.04333418, -0.05522346,  0.12183605, ..., -0.07099771,\n",
       "          0.11922012,  0.02772099],\n",
       "        ...,\n",
       "        [-0.07823251,  0.00454313, -0.00669663, ...,  0.1168596 ,\n",
       "         -0.04675003, -0.10465798],\n",
       "        [-0.0423265 , -0.09655887,  0.1030971 , ...,  0.11899669,\n",
       "          0.04664767,  0.05920129],\n",
       "        [-0.08052105, -0.04047733, -0.09403111, ..., -0.12012004,\n",
       "          0.05248372,  0.10803118]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'main_output_1/kernel:0' shape=(100, 48) dtype=float32, numpy=\n",
       " array([[ 0.10477787, -0.0784393 , -0.03089677, ..., -0.09879546,\n",
       "         -0.18920831, -0.01968068],\n",
       "        [ 0.11130786, -0.06273712, -0.0203467 , ...,  0.04174793,\n",
       "          0.03429839, -0.04813112],\n",
       "        [ 0.15115821, -0.10600448, -0.03186022, ..., -0.00992097,\n",
       "          0.18992195,  0.00709622],\n",
       "        ...,\n",
       "        [-0.06002893,  0.04700166, -0.1420802 , ...,  0.08173814,\n",
       "         -0.11480257,  0.14933392],\n",
       "        [-0.1485369 , -0.05889879, -0.18309782, ..., -0.11418024,\n",
       "          0.16326353,  0.15207592],\n",
       "        [-0.06733032,  0.12945855,  0.10054705, ..., -0.02281679,\n",
       "         -0.00834641,  0.08459765]], dtype=float32)>,\n",
       " <tf.Variable 'main_output_1/bias:0' shape=(48,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "#n_steps = len(X_train) // batch_size\n",
    "n_steps = 200\n",
    "optimizer = tf.keras.optimizers.Nadam(lr=learning_rate)\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "mean_loss = tf.keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y):\n",
    "    y_ = model(x)\n",
    "\n",
    "    return loss_object(y_true=y, y_pred=y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Initial Loss: 3.4878227710723877\n",
      "Step: 1, Loss: 3.255227565765381\n"
     ]
    }
   ],
   "source": [
    "X_batch, y_batch = get_batch(X_train, y_train)\n",
    "loss_value, grads = grad(model, X_batch, y_batch)\n",
    "print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                          loss_value.numpy()))\n",
    "\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "print(\"Step: {}, Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                  loss(model, X_batch, y_batch).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5\n",
      "WARNING:tensorflow:From /home/vijjus/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 000: Loss: 3.752, Accuracy: 0.320%s: 3.752, Accuracy: 0.320%\n",
      "Epoch: 1/5\n",
      "Epoch 001: Loss: 3.757, Accuracy: 0.310%s: 3.757, Accuracy: 0.310%\n",
      "Epoch: 2/5\n",
      "Epoch 002: Loss: 3.747, Accuracy: 0.332%s: 3.747, Accuracy: 0.332%\n",
      "Epoch: 3/5\n",
      "Step 80/200: [========            ] Loss: 3.749, Accuracy: 0.327%\r"
     ]
    }
   ],
   "source": [
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "for epoch in range(n_epochs + 1):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "    print(\"Epoch: {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        # Optimize the model\n",
    "        x, y = get_batch(X_train, y_train)\n",
    "        loss_value, grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        # Track progress\n",
    "        epoch_loss_avg(loss_value)  # Add current batch loss\n",
    "        # Compare predicted label to actual label\n",
    "        epoch_accuracy(y, model(x))\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            hashes = step // 10\n",
    "            ticker = '=' * hashes + ' ' * (20 - hashes)\n",
    "            print(\"Step {}/{}: [{}] Loss: {:.3f}, Accuracy: {:.3%}\".format(step, n_steps,\n",
    "                                                                        ticker,\n",
    "                                                                        epoch_loss_avg.result(),\n",
    "                                                                        epoch_accuracy.result()),\n",
    "                 end = '\\r')\n",
    "\n",
    "    # End epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small, y_train_small = X_train[:1000], y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.6609 - acc: 0.8026\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 49s 2s/step - loss: 0.4104 - acc: 0.8752\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 49s 2s/step - loss: 0.2471 - acc: 0.9398\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 49s 2s/step - loss: 0.1326 - acc: 0.9733\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 50s 2s/step - loss: 0.0650 - acc: 0.9942\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 50s 2s/step - loss: 0.0333 - acc: 0.9995\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 50s 2s/step - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 50s 2s/step - loss: 0.0124 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 51s 3s/step - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 50s 2s/step - loss: 0.0065 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f376ae97358>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_small, y_train_small, epochs=10, batch_size=32, steps_per_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
