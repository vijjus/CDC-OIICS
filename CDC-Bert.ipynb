{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vijjus/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vijjus/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vijjus/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vijjus/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vijjus/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vijjus/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/vijjus/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vijjus/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vijjus/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vijjus/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vijjus/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vijjus/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  1.14.0\n",
      "Hub version:  0.7.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy, categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed\n",
    "\n",
    "print(\"TF version: \", tf.__version__)\n",
    "print(\"Hub version: \", hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_bert_path =   '/home/vijjus/bert/bert/'\n",
    "data_path = '/home/vijjus/datasets/'  # path to ner_dataset.csv file , from \n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "\n",
    "# make sure that the paths are accessible within the notebook\n",
    "sys.path.insert(0,local_bert_path)\n",
    "sys.path.insert(0,data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vijjus/bert/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import optimization\n",
    "import run_classifier\n",
    "import tokenization\n",
    "import run_classifier_with_tfhub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will limit the sentences to 64 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow hub path to BERT module of choice\n",
    "bert_url = \"https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1\"\n",
    "\n",
    "# Define maximal length of input 'sentences' (post tokenization).\n",
    "max_length = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing ##\n",
    "\n",
    "BERT uses the wordpiece tokenizer. With this tokenizer, the original CDC dataset can be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(bert_url)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vijjus/bert/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vijjus/bert/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWord(word):\n",
    "    \"\"\"\n",
    "    \n",
    "    arguments: word\n",
    "    returns: dictionary with tokens and labels\n",
    "    \"\"\"\n",
    "    # the dataset contains various '\"\"\"' combinations which we choose to truncate to '\"', etc. \n",
    "    if word == '\"\"\"\"':\n",
    "        word = '\"'\n",
    "    elif word == '``':\n",
    "        word = '`'\n",
    "        \n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n",
    "    \n",
    "    addDict = dict()\n",
    "    \n",
    "    addDict['wordToken'] = tokens\n",
    "    addDict['tokenLength'] = tokenLength\n",
    "    \n",
    "    return addDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path + 'cdc_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57YOM WITH CONTUSION TO FACE AFTER STRIKING IT...</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A 45YOM FELL ON ARM WHILE WORKING HAD SLIPPED ...</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58YOM WITH CERVICAL STRAIN  BACK PAIN S P REST...</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33 YOM LAC TO HAND FROM A RAZOR KNIFE</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53YOM AT WORK IN A WAREHOUSE DOING UNSPECIFIED...</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sex  age  event\n",
       "0  57YOM WITH CONTUSION TO FACE AFTER STRIKING IT...    1   57     62\n",
       "1  A 45YOM FELL ON ARM WHILE WORKING HAD SLIPPED ...    1   45     42\n",
       "2  58YOM WITH CERVICAL STRAIN  BACK PAIN S P REST...    1   58     26\n",
       "3              33 YOM LAC TO HAND FROM A RAZOR KNIFE    1   33     60\n",
       "4  53YOM AT WORK IN A WAREHOUSE DOING UNSPECIFIED...    1   53     71"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b313269422434ca6a7fca3300c1bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=153956), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read the file line by line and construct sentences. A sentence end is marked by the word 'sentence' in the next row.\n",
    "You need to take care of that. Also, you need to cap sentence length using max_length. Sentences which are shorter than \n",
    "max_length need to be padded. Also, we choose to end all sentences with a [SEP] token, padded or not. \n",
    "\"\"\"\n",
    "\n",
    "# lists for sentences, tokens, labels, etc.  \n",
    "sentenceList = []\n",
    "sentenceTokenList = []\n",
    "sentLengthList = []\n",
    "\n",
    "# lists for BERT input\n",
    "bertSentenceIDs = []\n",
    "bertMasks = []\n",
    "bertSequenceIDs = []\n",
    "\n",
    "labels = []\n",
    "\n",
    "total_len = len(df)\n",
    "\n",
    "for i in tqdm_notebook(range(total_len)):\n",
    "    \n",
    "    # always start with [CLS] tokens\n",
    "    sentenceTokens = ['[CLS]']\n",
    "    \n",
    "    text = df.iloc[i]['text'].lower()\n",
    "    \n",
    "    labels.append(int(df.iloc[i]['event']))\n",
    "    \n",
    "    words = text.split(\" \")\n",
    "    \n",
    "    for word in words:\n",
    "        addDict = addWord(word)\n",
    "        sentenceTokens += addDict['wordToken']\n",
    "    sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
    "    \n",
    "    sentenceList.append(text)\n",
    "    sentenceTokenList.append(sentenceTokens)\n",
    "    sentLengthList.append(len(sentenceTokens))\n",
    "\n",
    "    sentenceLength = min(max_length - 1, len(sentenceTokens))\n",
    "    bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
    "    bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length - 1 - sentenceLength))\n",
    "    bertSequenceIDs.append([0] * (max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'58yom with cervical strain  back pain s p restrained taxi driver in low speed rear end mvc no loc no ab deployed'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceList[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153956"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.9370e+03, 5.4920e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        4.8000e+01, 5.0000e+01, 1.2990e+03, 2.7880e+03, 8.4400e+02,\n",
       "        2.0000e+00, 1.2320e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.5620e+03, 2.2173e+04, 3.8600e+02, 0.0000e+00,\n",
       "        0.0000e+00, 5.2000e+01, 9.7000e+02, 3.9070e+03, 1.1678e+04,\n",
       "        0.0000e+00, 8.9860e+03, 5.2000e+01, 3.3460e+04, 4.4290e+03,\n",
       "        2.9330e+03, 9.6000e+01, 3.1225e+04, 9.0780e+03, 4.0000e+00,\n",
       "        0.0000e+00, 8.8800e+02, 1.2000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.3730e+03]),\n",
       " array([10.        , 11.85416667, 13.70833333, 15.5625    , 17.41666667,\n",
       "        19.27083333, 21.125     , 22.97916667, 24.83333333, 26.6875    ,\n",
       "        28.54166667, 30.39583333, 32.25      , 34.10416667, 35.95833333,\n",
       "        37.8125    , 39.66666667, 41.52083333, 43.375     , 45.22916667,\n",
       "        47.08333333, 48.9375    , 50.79166667, 52.64583333, 54.5       ,\n",
       "        56.35416667, 58.20833333, 60.0625    , 61.91666667, 63.77083333,\n",
       "        65.625     , 67.47916667, 69.33333333, 71.1875    , 73.04166667,\n",
       "        74.89583333, 76.75      , 78.60416667, 80.45833333, 82.3125    ,\n",
       "        84.16666667, 86.02083333, 87.875     , 89.72916667, 91.58333333,\n",
       "        93.4375    , 95.29166667, 97.14583333, 99.        ]),\n",
       " <a list of 48 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(labels, bins=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bertSequenceIDs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([     0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0., 153956.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.]),\n",
       " array([63.5       , 63.51612903, 63.53225806, 63.5483871 , 63.56451613,\n",
       "        63.58064516, 63.59677419, 63.61290323, 63.62903226, 63.64516129,\n",
       "        63.66129032, 63.67741935, 63.69354839, 63.70967742, 63.72580645,\n",
       "        63.74193548, 63.75806452, 63.77419355, 63.79032258, 63.80645161,\n",
       "        63.82258065, 63.83870968, 63.85483871, 63.87096774, 63.88709677,\n",
       "        63.90322581, 63.91935484, 63.93548387, 63.9516129 , 63.96774194,\n",
       "        63.98387097, 64.        , 64.01612903, 64.03225806, 64.0483871 ,\n",
       "        64.06451613, 64.08064516, 64.09677419, 64.11290323, 64.12903226,\n",
       "        64.14516129, 64.16129032, 64.17741935, 64.19354839, 64.20967742,\n",
       "        64.22580645, 64.24193548, 64.25806452, 64.27419355, 64.29032258,\n",
       "        64.30645161, 64.32258065, 64.33870968, 64.35483871, 64.37096774,\n",
       "        64.38709677, 64.40322581, 64.41935484, 64.43548387, 64.4516129 ,\n",
       "        64.46774194, 64.48387097, 64.5       ]),\n",
       " <a list of 62 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentenceLengths= [l for l in sentLengthList]\n",
    "\n",
    "plt.hist(np.array(sentenceLengths), bins=(max_length-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 153956, 64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bert_inputs[0])\n",
    "np.random.seed(0)\n",
    "training_examples = np.random.binomial(1, 0.7, numSentences)\n",
    "num_training_examples = np.sum(training_examples)\n",
    "num_test_examples = numSentences - num_training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153956"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[62, 42, 26, 60, 71, 62, 60, 69, 71, 71]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "event2id = {}\n",
    "id2event = {}\n",
    "events = sorted(set(labels))\n",
    "for i, event in enumerate(events):\n",
    "    event2id[event] = i\n",
    "    id2event[i] = event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "numClasses = df.event.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSentence_ids = []\n",
    "trainMasks = []\n",
    "trainSequence_ids = []\n",
    "\n",
    "testSentence_ids = []\n",
    "testMasks = []\n",
    "testSequence_ids = []\n",
    "\n",
    "Labels_train_list = []\n",
    "Labels_test_list = []\n",
    "\n",
    "for example in range(numSentences):\n",
    "    if training_examples[example] == 1:\n",
    "        trainSentence_ids.append(bert_inputs[0][example])\n",
    "        trainMasks.append(bert_inputs[1][example])\n",
    "        trainSequence_ids.append(bert_inputs[2][example])\n",
    "        Labels_train_list.append(event2id[labels[example]])\n",
    "    else:\n",
    "        testSentence_ids.append(bert_inputs[0][example])\n",
    "        testMasks.append(bert_inputs[1][example])\n",
    "        testSequence_ids.append(bert_inputs[2][example])\n",
    "        Labels_test_list.append(event2id[labels[example]])\n",
    "        \n",
    "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
    "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
    "\n",
    "Labels_train = np.zeros((num_training_examples,numClasses), dtype=np.float32)\n",
    "Labels_test = np.zeros((num_test_examples,numClasses), dtype=np.float32)\n",
    "\n",
    "for x, label in enumerate(Labels_train_list):\n",
    "    Labels_train[x][label] = 1.0\n",
    "    \n",
    "for x, label in enumerate(Labels_test_list):\n",
    "    Labels_test[x][label] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(id2event[np.argmax(Labels_train[0])] == labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 107628, 64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n",
    "k_start = 0\n",
    "k_end = -1\n",
    "\n",
    "if k_end == -1:\n",
    "    k_end_train = X_train[0].shape[0]\n",
    "    k_end_test = X_test[0].shape[0]\n",
    "else:\n",
    "    k_end_train = k_end_test = k_end\n",
    "    \n",
    "bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n",
    "                       X_train[2][k_start:k_end_train]]\n",
    "bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n",
    "                      X_test[2][k_start:k_end_test]]\n",
    "\n",
    "labels_train_k = Labels_train[k_start:k_end_train]\n",
    "labels_test_k = Labels_test[k_start:k_end_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107628, 48)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train_k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46328, 48)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test_k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss function explicitly, filtering out 'extra inserted labels'\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length + 1) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns:  cost\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    #y_label = tf.reshape(tf.layers.Flatten()(tf.cast(y_true, tf.int32)),[-1])\n",
    "    \n",
    "    #mask = (y_label < 17)   # This mask is used to remove all tokens that do not correspond to the original base text.\n",
    "\n",
    "    #y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n",
    "    \n",
    "    #y_flat_pred = tf.reshape(tf.layers.Flatten()(tf.cast(y_pred, tf.float32)),[-1, numClasses])\n",
    "    \n",
    "    #y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n",
    "    \n",
    "    return tf.reduce_mean(categorical_crossentropy(y_true, y_pred, from_logits=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss dfunction filtering out also the newly inserted labels\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns: accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    y_label = tf.math.argmax(input = tf.reshape(tf.layers.Flatten()(tf.cast(y_true, tf.float64)),\n",
    "                                                [-1, numClasses]), axis=1)\n",
    "    #y_label = tf.reshape(tf.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    #mask = (y_label < 17)\n",
    "    #y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numClasses]), axis=1)\n",
    "    \n",
    "    #y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted, y_label), dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_customized = tf.keras.optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Create BERT layer, following https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b\n",
    "    init:  initialize layer. Specify various parameters regarding output types and dimensions. Very important is\n",
    "           to set the number of trainable layers.\n",
    "    build: build the layer based on parameters\n",
    "    call:  call the BERT layer within a model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"first\",\n",
    "        bert_url=\"https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_url = bert_url\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_url, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "        trainable_layers = []\n",
    "\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "\n",
    "        # mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdc_model(max_input_length, train_layers):\n",
    "    \"\"\"\n",
    "    Implementation of CDC model\n",
    "    \n",
    "    variables:\n",
    "        max_input_length: number of tokens (max_length + 1)\n",
    "        train_layers: number of layers to be retrained\n",
    "        optimizer: optimizer to be used\n",
    "    \n",
    "    returns: model\n",
    "    \"\"\"\n",
    "    \n",
    "    in_id = tf.keras.layers.Input(shape=(max_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_length,), name=\"segment_ids\")\n",
    "    \n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    bert_sequence = BertLayer(n_fine_tune_layers=train_layers)(bert_inputs)\n",
    "    \n",
    "    print(bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
    "    \n",
    "    pred = tf.keras.layers.Dense(48, activation='softmax', name='cdc')(dense)\n",
    "     \n",
    "    print('pred: ', pred)\n",
    "    \n",
    "    ## Prepare for multipe loss functions, although not used here\n",
    "    \n",
    "    losses = {\"cdc\": custom_loss}\n",
    "    lossWeights = {\"cdc\": 1.0}\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    \n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer='adam',\n",
    "    #              metrics=['accuracy'])                                                \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"bert_layer_6/bert_layer_6_module_apply_tokens/bert/pooler/dense/Tanh:0\", shape=(?, 768), dtype=float32)\n",
      "pred:  Tensor(\"cdc_6/Softmax:0\", shape=(?, 48), dtype=float32)\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_6 (BertLayer)        (None, 768)          108931396   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      bert_layer_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "cdc (Dense)                     (None, 48)           12336       dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,140,596\n",
      "Trainable params: 28,560,688\n",
      "Non-trainable params: 80,579,908\n",
      "__________________________________________________________________________________________________\n",
      "Train on 107628 samples, validate on 46328 samples\n",
      "Epoch 1/8\n",
      "107628/107628 [==============================] - 1924s 18ms/sample - loss: 2.7855 - acc: 0.1644 - val_loss: 2.7639 - val_acc: 0.1585\n",
      "Epoch 2/8\n",
      "107616/107628 [============================>.] - ETA: 0s - loss: 2.7644 - acc: 0.1655"
     ]
    }
   ],
   "source": [
    "#Start session\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "model = cdc_model(max_length + 1, train_layers=4)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_k, \n",
    "    {\"cdc\": labels_train_k },\n",
    "    validation_data=(bert_inputs_test_k, {\"cdc\": labels_test_k }),\n",
    "    epochs=8,\n",
    "    batch_size=32#,\n",
    "    #callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
